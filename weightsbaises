Layer 1 (Input -> Hidden): 208 -> 128
  Weights shape: (128, 208)
  Weight sample (first 3x3):
[[ 0.10855731 -0.01785661  0.00824521]
 [-0.06648077  0.03052817 -0.05264307]
 [-0.18035692 -0.14268559  0.10165065]]
  Biases shape: (128,)
  Bias sample (first 10):
[ 4.38976258e-07  1.07604853e-06  4.83104850e-06 -2.22543463e-06
  1.03189905e-05  1.42603049e-05  3.68463589e-06  3.61402226e-06
  6.57743567e-06  7.54197345e-07]

Layer 2 (Hidden -> Hidden): 128 -> 64
  Weights shape: (64, 128)
  Weight sample (first 3x3):
[[ 0.09705641 -0.05726784  0.13276774]
 [-0.05799779 -0.28219387 -0.17868204]
 [-0.16743504  0.04216655 -0.26262274]]
  Biases shape: (64,)
  Bias sample (first 10):
[-3.9332263e-06 -2.8214656e-06 -2.7604676e-06  5.4778066e-06
  3.5596745e-06 -2.9172147e-06 -1.2051606e-06  1.9858478e-06
 -1.1112684e-06  8.8219713e-06]

Layer 3 (Hidden -> Output): 64 -> 15
  Weights shape: (15, 64)
  Weights (first 5 rows):
[[-1.24759357e-02  5.14741316e-02  1.23361461e-01 -6.23534545e-02
   2.59597655e-02 -3.90699320e-03  3.22898701e-02  7.49096498e-02
  -2.05085967e-02  1.74500421e-02 -2.35283617e-02  1.89646613e-02
  -1.27753559e-02 -6.07727356e-02 -4.75315414e-02 -1.67488940e-02
   2.90957466e-02 -8.61678794e-02  3.54726203e-02  4.91915978e-02
  -7.90209323e-02  2.19304161e-03 -6.62553608e-02 -3.58760506e-02
  -4.13947701e-02 -5.68512566e-02 -1.62910014e-01 -6.16562888e-02
  -2.13727757e-01  7.07385084e-03  1.42237358e-03  3.33062820e-02
  -1.22848740e-02  4.14521918e-02  7.89630711e-02  1.62162662e-01
   4.56730798e-02 -7.43597373e-02 -5.02137542e-02 -1.55771188e-02
   8.19117799e-02  1.20306984e-01  3.30582149e-02  1.81602649e-02
  -2.73835845e-02  9.23381001e-03 -3.23865283e-03 -8.49789083e-02
  -1.28286313e-02  4.95729297e-02  8.26228634e-02 -7.36168101e-02
   6.28896803e-02  5.55279516e-02 -4.80932184e-03  1.68223158e-02
  -2.26598419e-02 -1.15874615e-02 -4.41286042e-02 -8.81044939e-02
   8.84426162e-02  2.09162831e-02 -6.10935874e-03 -1.29707336e-01]
 [ 3.15591283e-02 -3.62579115e-02 -1.68985222e-02  3.12014259e-02
  -2.07340922e-02  2.12924723e-02  1.03084007e-02 -3.04246712e-02
  -8.73408653e-03 -2.69837100e-02 -6.28075143e-03 -1.00628968e-04
  -4.80333064e-03  3.18162628e-02  6.94504892e-03  3.72805959e-03
   7.37949228e-03  1.14819286e-02  2.09504925e-02 -2.09003650e-02
   2.36480143e-02  3.74979414e-02  1.05041098e-02  2.93126260e-03
   4.55664983e-03  4.50114273e-02  3.16364430e-02 -1.08006243e-02
   7.10544409e-03 -5.22814505e-02  4.84769652e-03  2.77046748e-02
  -1.61445420e-02  5.48150903e-03 -2.68681105e-02  4.10648296e-03
  -3.34359892e-02 -1.59554817e-02  6.14650035e-03  1.53789273e-03
  -1.38262017e-02  3.12369224e-02  5.40897204e-03 -8.79281200e-03
   7.66995642e-03 -8.61158408e-03 -1.90766063e-02  3.72821130e-02
   1.37775838e-02  1.26736322e-02 -1.70826372e-02  2.01496910e-02
   4.23050374e-02 -1.74417701e-02  4.96471301e-03 -9.13174357e-03
  -2.02481914e-02  1.27635356e-02 -7.17112888e-03 -7.21683772e-03
   4.72236332e-03 -2.30488414e-03  4.82434640e-03 -4.09646612e-03]
 [-2.57285889e-02  5.48558086e-02  1.11716986e-01 -5.45834936e-02
   2.51437239e-02  4.52282950e-02  3.95925604e-02  6.80127069e-02
  -2.54777931e-02  4.56661591e-03 -1.91954952e-02  2.55793761e-02
   6.64589256e-02 -2.15460993e-02 -3.98215465e-02  1.43175945e-04
   4.19859439e-02 -9.10208896e-02  5.01681790e-02  8.01655203e-02
  -7.24079311e-02  5.27815521e-02 -5.24163805e-02 -5.16290888e-02
  -6.51412830e-02 -7.70542100e-02 -1.07563667e-01 -6.40733540e-02
  -1.60496891e-01  2.65465286e-02  2.00262889e-02  2.18794160e-02
  -8.67047627e-03  5.98410331e-02  7.13157356e-02  2.20040008e-01
   3.49909998e-02 -7.04851374e-02 -6.24824688e-02 -2.17806362e-02
   6.89859986e-02  1.99096754e-01  2.40928773e-02  4.74453019e-03
  -1.54208830e-02  7.64689734e-03  1.78877227e-02 -9.04488266e-02
  -1.85603835e-02  2.68406346e-02  7.27319717e-02 -6.82070479e-02
   9.22815502e-02  6.68141022e-02 -9.61855613e-03  1.64396949e-02
  -3.10275275e-02 -1.76814739e-02 -3.36147957e-02 -4.43673916e-02
   1.15513697e-01  1.33979265e-02  8.33915733e-03 -1.09408550e-01]
 [-7.99077004e-03  6.63885102e-02 -6.40164092e-02 -3.25268507e-02
   5.27310222e-02  7.97550082e-02  2.12508328e-02  1.33751974e-01
   6.33685812e-02 -2.13615019e-02 -4.12066001e-05  8.25841911e-03
   1.56950772e-01  1.10294111e-01  7.83073809e-03  8.30957666e-02
  -1.84298344e-02 -1.51233906e-02  4.54441793e-02  5.03464267e-02
   1.67930629e-02  1.60538673e-01 -3.58999590e-03 -6.40324056e-02
  -1.07735079e-02 -4.96696308e-02  9.17106047e-02 -7.60974735e-02
   8.99104774e-02  1.23405769e-01  1.71497259e-02 -6.09801225e-02
  -3.49234487e-03  1.49318008e-02  4.24181558e-02  1.09331366e-02
   9.40728411e-02  1.04850763e-02 -3.55740637e-02  8.19310024e-02
   1.72187593e-02  5.92103675e-02 -3.31733935e-03 -2.09775958e-02
   1.67554189e-02 -1.52344592e-02 -2.19084835e-03 -1.29710302e-01
  -7.59361982e-02 -3.24586555e-02  3.10991574e-02 -7.49059627e-03
  -6.70045707e-03 -4.56737354e-03 -2.05582045e-02  5.20678312e-02
   4.38650660e-02 -1.34784859e-02  1.17761374e-01  9.08173472e-02
  -3.07150767e-03  1.56083889e-02  1.57326106e-02 -1.19077321e-03]
 [ 5.92806220e-01  4.09917146e-01  1.48824155e-01  3.48220795e-01
   3.03024590e-01  8.78851712e-02  3.56774926e-01  2.00614423e-01
   2.70625353e-01  3.12823474e-01  5.54685354e-01  2.30264455e-01
   2.62463957e-01  9.80775878e-02  4.73641336e-01  9.51882750e-02
   5.93466222e-01  2.86993645e-02  3.67139578e-01  5.64584315e-01
   1.26544744e-01  4.26028073e-02  2.45488629e-01  4.36764419e-01
  -1.28822876e-02  4.70475316e-01  1.56145707e-01  6.27833009e-02
  -8.44852719e-03  4.23945747e-02  3.71010125e-01  5.35582185e-01
   6.34608269e-01  3.82613957e-01  3.47278416e-01  5.13902783e-01
   7.93303400e-02  4.29963350e-01  2.92503029e-01  1.87558278e-01
   3.41979176e-01  3.27454925e-01  5.10024428e-01  4.80507255e-01
   6.27361119e-01  1.27020091e-01  5.16011834e-01 -3.32038216e-02
   2.52222091e-01  1.47551566e-01  1.54867172e-01  8.05355236e-02
   7.78475450e-03  2.68700277e-03  6.41363204e-01  4.99781936e-01
   9.59390681e-03 -9.28759668e-03  5.56431830e-01  3.24931517e-02
   4.95928317e-01  5.06089747e-01  5.19511819e-01  1.23998381e-01]]
  Biases shape: (15,)
  Biases (full):
[-0.17828637 -0.24878529  0.00276563  0.37107897  0.42860207 -0.15089874
 -0.24386756 -0.03280782  0.12318541  0.18490623 -0.04571814 -0.21959661
  0.02401303 -0.05214475 -0.07353075]

Batch Norm Parameters:
  BN1 weights: (128,)
  BN2 weights: (64,)

Extracting weights and biases...
Weights and biases saved to:
- lif_snn_weights_biases.pkl (for Python)
- lif_snn_weights_biases.json (human readable)
